{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with mnist dataset using ensemble classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mnist, y_mnist = fetch_openml('mnist_784', return_X_y=True, as_frame=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mnist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_mnist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1) split the data into training and test sets\n",
    "X_train, y_train = X_mnist[:60000], y_mnist[:60000]\n",
    "X_test, y_test = X_mnist[60_000:], y_mnist[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Use principal component analysis (PCA) to reduce the dimensions of the system and preserve 90% of\n",
    "#the training setâ€™s variance.\n",
    "pca = PCA(0.90)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 87)\n",
      "(10000, 87)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Train a Decision Tree with maximum depth equal to 10, a Random Forest with 50 estimators, an AdaBoost with 50 estimators, a LinearSVC with maximum iterations equal to 500, and a Logistic Regression\n",
    "#with maximum iterations equal to 500 classifier on the training set and calculate the score of each one of\n",
    "#the estimators on the test set.\n",
    "dec_trees_clf = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
    "random_forest_clf = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1), n_estimators=50, random_state=42)\n",
    "svm_clf = LinearSVC(max_iter=500, tol=20, random_state=42)\n",
    "lr_pipe = make_pipeline(StandardScaler(), LogisticRegression(max_iter=500, random_state=42))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine them in a list of tuples with the name and the estimator\n",
    "named_estimators = [(\"random_forest\", random_forest_clf),\n",
    "                    (\"svm\", svm_clf),\n",
    "                    (\"dec_trees\", dec_trees_clf),\n",
    "                    (\"adaboost\", ada_clf),\n",
    "                    (\"Logistic_regression\", lr_pipe)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the RandomForestClassifier(n_estimators=50, random_state=42)\n",
      "Training the LinearSVC(max_iter=500, random_state=42, tol=20)\n",
      "Training the DecisionTreeClassifier(max_depth=10, random_state=42)\n",
      "Training the AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),\n",
      "                   random_state=42)\n",
      "Training the Pipeline(steps=[('standardscaler', StandardScaler()),\n",
      "                ('logisticregression',\n",
      "                 LogisticRegression(max_iter=500, random_state=42))])\n"
     ]
    }
   ],
   "source": [
    "# train and calculate the score of each one of the estimators on the test set\n",
    "scores = {}\n",
    "for named_estimator in named_estimators:\n",
    "    name, estimator = named_estimator\n",
    "    print(\"Training the\", estimator)\n",
    "    estimator.fit(X_train, y_train)\n",
    "    score = estimator.score(X_test, y_test)\n",
    "    scores[name] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores:\n",
      "random_forest: 0.9468\n",
      "svm: 0.6247\n",
      "dec_trees: 0.7970\n",
      "adaboost: 0.7152\n",
      "Logistic_regression: 0.9193\n"
     ]
    }
   ],
   "source": [
    "print(\"Scores:\")\n",
    "for clf_name, clf_score in scores.items():\n",
    "    print (f\"{clf_name}: {clf_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(cv=3,\n",
       "                   estimators=[('random_forest',\n",
       "                                RandomForestClassifier(n_estimators=50,\n",
       "                                                       random_state=42)),\n",
       "                               ('svm',\n",
       "                                LinearSVC(max_iter=500, random_state=42,\n",
       "                                          tol=20)),\n",
       "                               ('dec_trees',\n",
       "                                DecisionTreeClassifier(max_depth=10,\n",
       "                                                       random_state=42)),\n",
       "                               ('adaboost',\n",
       "                                AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1),\n",
       "                                                   random_state=42)),\n",
       "                               ('Logistic_regression',\n",
       "                                Pipeline(steps=[('standardscaler',\n",
       "                                                 StandardScaler()),\n",
       "                                                ('logisticregression',\n",
       "                                                 LogisticRegression(max_iter=500,\n",
       "                                                                    random_state=42))]))],\n",
       "                   final_estimator=RandomForestClassifier(random_state=43))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4) create the stacking classifier with 3-fold cross validation and \n",
    "# a Random Forest Classifier as the final estimator and train it.\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=named_estimators,\n",
    "    final_estimator=RandomForestClassifier(random_state=43),\n",
    "    cv=3\n",
    "    )\n",
    "stacking_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking score: 0.9559\n"
     ]
    }
   ],
   "source": [
    "# 5) What is the score of the Stacking Classifier on the test set? How much better does it perform compared\n",
    "#to the individual classifiers?\n",
    "stacking_score = stacking_clf.score(X_test, y_test)\n",
    "print (f\"Stacking score: {stacking_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The stacking classifier performs better by:\n",
      "1.0% than the random_forest\n",
      "34.6% than the svm\n",
      "16.6% than the dec_trees\n",
      "25.2% than the adaboost\n",
      "3.8% than the Logistic_regression\n"
     ]
    }
   ],
   "source": [
    "print(\"The stacking classifier performs better by:\")\n",
    "for clf_name, clf_score in scores.items():\n",
    "    print (f\"{100*(stacking_score-clf_score)/stacking_score:.1f}% than the {clf_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
